{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5uTi_Fbqu05N"
   },
   "source": [
    "#  Particle Swarm Optimized  Convulutional Neural Network for Human Activity Recognition \n",
    "\n",
    "Activity Recognition aims at identifying the activity of users based on series of observations collected during the activity in a definite context environment.  Applications that are enabled with activity recognition are gaining huge attention, as users get personalized services and support based on their contextual behaviour. The proliferation of wearable devices and smartphones has provided real-time monitoring of human activities through sensors that are embedded in smart devices such as proximity sensors, cameras, microphone, magnetometers accelerometers, gyroscopes, GPS etc., Thus, understanding human activities in inferring the gesture or position has created a competitive challenge in building personal health care systems, examining wellness and fit characteristics, and most pre-dominantly in elderly care, abnormal activity detection, diabetes or epilepsy disorders etc.,\n",
    "\n",
    "\n",
    "Initially, Human Activity Recognition (HAR) were carried out by attaching one or more dedicated on-body sensors to specific parts of human body to collect data [1–3].  As, the usage of smart phones for daily activities has increased extensively, HAR research has employed to collect data from built-in sensors embedded in smart phones. [4–6]. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "fAKjg-bKvR0v",
    "outputId": "ae8e0d13-a353-447d-9ba3-c9108384c11c"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 557
    },
    "colab_type": "code",
    "id": "iUhdotvP0OHn",
    "outputId": "3e0c3533-178b-4981-e385-c6cc7f9b3117"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "pip install pandas==0.20.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9H8eaMITu05T"
   },
   "source": [
    "# Problem Statement #\n",
    "\n",
    " + Activity Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "F0f3wAx4u05U",
    "outputId": "c3dd7154-8996-47df-ae73-8ffe437a6c1d"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# get the features from the file features.txt\n",
    "features = list()\n",
    "with open('/content/gdrive/My Drive/UCI HAR Dataset/UCI HAR Dataset/features.txt') as f:\n",
    "    features = [line.split()[1] for line in f.readlines()]\n",
    "print('No of Features: {}'.format(len(features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nE4ENxyMu05Y"
   },
   "source": [
    "# Train the Data #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "colab_type": "code",
    "id": "iIKe892tu05Y",
    "outputId": "bcd204c8-f078-4562-a3e1-cdfc9143ebd1"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# get the data from txt files to pandas dataffame\n",
    "X_train = pd.read_csv('/content/gdrive/My Drive/UCI HAR Dataset/UCI HAR Dataset/train/X_train.txt', delim_whitespace=True, header=None, names=features)\n",
    "\n",
    "# add subject column to the dataframe\n",
    "X_train['subject'] = pd.read_csv('/content/gdrive/My Drive/UCI HAR Dataset/UCI HAR Dataset/train/subject_train.txt', header=None, squeeze=True)\n",
    "\n",
    "y_train = pd.read_csv('/content/gdrive/My Drive/UCI HAR Dataset/UCI HAR Dataset/train/y_train.txt', names=['Activity'], squeeze=True)\n",
    "y_train_labels = y_train.map({1: 'WALKING', 2:'WALKING_UPSTAIRS',3:'WALKING_DOWNSTAIRS',\\\n",
    "                       4:'SITTING', 5:'STANDING',6:'LAYING'})\n",
    "\n",
    "# put all columns in a single dataframe\n",
    "train = X_train\n",
    "train['Activity'] = y_train\n",
    "train['ActivityName'] = y_train_labels\n",
    "train.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Y6Wj-udtu05h",
    "outputId": "4c042aed-2eec-4d4e-d2a0-067c10f2ce6d",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yc7lm3G4u05j"
   },
   "source": [
    "# Test Data #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "colab_type": "code",
    "id": "_N5a6ieMu05k",
    "outputId": "23efe774-dea1-4c1f-c954-a8867de00df6"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# get the data from txt files to pandas dataffame\n",
    "X_test = pd.read_csv('/content/gdrive/My Drive/UCI HAR Dataset/UCI HAR Dataset/test/X_test.txt', delim_whitespace=True, header=None, names=features)\n",
    "\n",
    "# add subject column to the dataframe\n",
    "X_test['subject'] = pd.read_csv('/content/gdrive/My Drive/UCI HAR Dataset/UCI HAR Dataset/test/subject_test.txt', header=None, squeeze=True)\n",
    "\n",
    "# get y labels from the txt file\n",
    "y_test = pd.read_csv('/content/gdrive/My Drive/UCI HAR Dataset/UCI HAR Dataset/test/y_test.txt', names=['Activity'], squeeze=True)\n",
    "y_test_labels = y_test.map({1: 'WALKING', 2:'WALKING_UPSTAIRS',3:'WALKING_DOWNSTAIRS',\\\n",
    "                       4:'SITTING', 5:'STANDING',6:'LAYING'})\n",
    "\n",
    "\n",
    "# Single Frame #\n",
    "test = X_test\n",
    "test['Activity'] = y_test\n",
    "test['ActivityName'] = y_test_labels\n",
    "test.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "nD0iiWkhu05m",
    "outputId": "b1539491-8644-465f-93d0-015b5c13ae85"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "2G1AzIgfu05o",
    "outputId": "c781047e-826e-4a3c-be8d-97515a0279e6"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ELKAs6dFu05q"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "nESanfXgu05r"
   },
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kJF9SCuvu05r"
   },
   "source": [
    "# Duplicates to Check #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "FS5_UteZu05r",
    "outputId": "6ae3ab6c-9dc3-4ad4-8031-183a236120e6",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print('No of duplicates in train: {}'.format(sum(train.duplicated())))\n",
    "print('No of duplicates in test : {}'.format(sum(test.duplicated())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "byQXsl2zu05t"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dI4Q5kXHu05u"
   },
   "source": [
    "# Check for Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "okhgD-lIu05u",
    "outputId": "b8594046-f3cf-48c5-9a7e-6a70f78a3436"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print('We have {} NaN/Null values in train'.format(train.isnull().values.sum()))\n",
    "print('We have {} NaN/Null values in test'.format(test.isnull().values.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SwojCtHRu05x"
   },
   "source": [
    "## 3. Check for data imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "El2nbDGwu05x"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 474
    },
    "colab_type": "code",
    "id": "oHPkub7su05z",
    "outputId": "aed8b12a-49d0-481c-bee9-30795d634ed7"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.title('Data provided by each user', fontsize=20)\n",
    "sns.countplot(x='subject',hue='ActivityName', data = train)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "colab_type": "code",
    "id": "5p-1Mz7yu051",
    "outputId": "737d6c6a-7619-4b87-9284-e68686408764",
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "plt.title('No of Datapoints per Activity', fontsize=15)\n",
    "sns.countplot(train.ActivityName)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GDcdcSdYu054"
   },
   "source": [
    "# Changing feature names # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "Usfg_dlBu054",
    "outputId": "5ec97801-640e-411b-ada4-c1d09804da71"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "columns = train.columns\n",
    "\n",
    "# Removing '()' from column names\n",
    "columns = columns.str.replace('[()]','')\n",
    "columns = columns.str.replace('[-]', '_')\n",
    "columns = columns.str.replace('[,]','')\n",
    "\n",
    "train.columns = columns\n",
    "test.columns = columns\n",
    "\n",
    "test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JHOpfepFu056"
   },
   "source": [
    "# Save this dataframe in a csv files #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aTyswQuJu056"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "train.to_csv('/content/gdrive/My Drive/UCI HAR Dataset/UCI HAR Dataset/csv_files/train.csv', index=False)\n",
    "test.to_csv('/content/gdrive/My Drive/UCI HAR Dataset/UCI HAR Dataset/csv_files/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D5sKTQSFu059"
   },
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1p_f9fvHu05-"
   },
   "source": [
    "### 2. Stationary and Moving activities are completely different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "colab_type": "code",
    "id": "eocLkZqqu05-",
    "outputId": "a36e5d6e-cd24-468d-be68-6f9785f952b3"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "sns.set_palette(\"Set1\", desat=0.80)\n",
    "facetgrid = sns.FacetGrid(train, hue='ActivityName', size=6,aspect=2)\n",
    "facetgrid.map(sns.distplot,'tBodyAccMag_mean', hist=False)\\\n",
    "    .add_legend()\n",
    "plt.annotate(\"Stationary Activities\", xy=(-0.956,14), xytext=(-0.9, 23), size=20,\\\n",
    "            va='center', ha='left',\\\n",
    "            arrowprops=dict(arrowstyle=\"simple\",connectionstyle=\"arc3,rad=0.1\"))\n",
    "\n",
    "plt.annotate(\"Moving Activities\", xy=(0,3), xytext=(0.2, 9), size=20,\\\n",
    "            va='center', ha='left',\\\n",
    "            arrowprops=dict(arrowstyle=\"simple\",connectionstyle=\"arc3,rad=0.1\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "id": "Y4_N_9zlu06A",
    "outputId": "ac1189d0-d980-4a5e-966c-0ed36d70f7ae"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# for plotting purposes taking datapoints of each activity to a different dataframe\n",
    "df1 = train[train['Activity']==1]\n",
    "df2 = train[train['Activity']==2]\n",
    "df3 = train[train['Activity']==3]\n",
    "df4 = train[train['Activity']==4]\n",
    "df5 = train[train['Activity']==5]\n",
    "df6 = train[train['Activity']==6]\n",
    "\n",
    "plt.figure(figsize=(14,7))\n",
    "plt.subplot(2,2,1)\n",
    "plt.title('Stationary Activities(Zoomed in)')\n",
    "sns.distplot(df4['tBodyAccMag_mean'],color = 'r',hist = False, label = 'Sitting')\n",
    "sns.distplot(df5['tBodyAccMag_mean'],color = 'm',hist = False,label = 'Standing')\n",
    "sns.distplot(df6['tBodyAccMag_mean'],color = 'c',hist = False, label = 'Laying')\n",
    "plt.axis([-1.01, -0.5, 0, 35])\n",
    "plt.legend(loc='center')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.title('Moving Activities')\n",
    "sns.distplot(df1['tBodyAccMag_mean'],color = 'red',hist = False, label = 'Walking')\n",
    "sns.distplot(df2['tBodyAccMag_mean'],color = 'blue',hist = False,label = 'Walking Up')\n",
    "sns.distplot(df3['tBodyAccMag_mean'],color = 'green',hist = False, label = 'Walking down')\n",
    "plt.legend(loc='center right')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0SkimDKvu06C"
   },
   "source": [
    "### 3. Magnitude of an acceleration can saperate it well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "colab_type": "code",
    "id": "szlPBccUu06C",
    "outputId": "7418a32f-3110-412e-9663-70d015f86f8a",
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "sns.boxplot(x='ActivityName', y='tBodyAccMag_mean',data=train, showfliers=False, saturation=1)\n",
    "plt.ylabel('Acceleration Magnitude mean')\n",
    "plt.axhline(y=-0.7, xmin=0.1, xmax=0.9,dashes=(5,5), c='g')\n",
    "plt.axhline(y=-0.05, xmin=0.4, dashes=(5,5), c='m')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wetQLsECu06E"
   },
   "source": [
    "__ Observations__:\n",
    "- Let us consider If tAccMean is < -0.8 then the Activities are either Standing or Sitting or Laying.\n",
    "- If tAccMean is > -0.6 then the Activities are either Walking or WalkingDownstairs or WalkingUpstairs.\n",
    "- If tAccMean > 0.0 then the Activity is WalkingDownstairs.\n",
    "- We can classify 75% the Acitivity labels with some errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rZF8dQcVu06E"
   },
   "source": [
    "### 4. Position of GravityAccelerationComponants also matters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "colab_type": "code",
    "id": "dPk6QaYVu06E",
    "outputId": "716bf523-3f4f-4218-fe3b-ce91962c6802"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "sns.boxplot(x='ActivityName', y='angleXgravityMean', data=train)\n",
    "plt.axhline(y=0.08, xmin=0.1, xmax=0.9,c='m',dashes=(5,3))\n",
    "plt.title('Angle between X-axis and Gravity_mean', fontsize=15)\n",
    "plt.xticks(rotation = 40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v89Sr7EPu06G"
   },
   "source": [
    "__ Observations__:\n",
    "* If angleX,gravityMean > 0 then Activity is Laying.\n",
    "* We can classify all datapoints belonging to Laying activity with just a single if else statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "colab_type": "code",
    "id": "QQtC14sbu06G",
    "outputId": "94f1ef01-ace1-4d16-845a-d56c9f52f45e"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "sns.boxplot(x='ActivityName', y='angleYgravityMean', data = train, showfliers=False)\n",
    "plt.title('Angle between Y-axis and Gravity_mean', fontsize=15)\n",
    "plt.xticks(rotation = 40)\n",
    "plt.axhline(y=-0.22, xmin=0.1, xmax=0.8, dashes=(5,3), c='m')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MZl__dAGu06J"
   },
   "source": [
    "# Apply t-sne on the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pO19JDepu06J"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vky_xoLhu06L"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# performs t-sne with different perplexity values and their repective plots..\n",
    "\n",
    "def perform_tsne(X_data, y_data, perplexities, n_iter=1000, img_name_prefix='t-sne'):\n",
    "        \n",
    "    for index,perplexity in enumerate(perplexities):\n",
    "        # perform t-sne\n",
    "        print('\\nperforming tsne with perplexity {} and with {} iterations at max'.format(perplexity, n_iter))\n",
    "        X_reduced = TSNE(verbose=2, perplexity=perplexity).fit_transform(X_data)\n",
    "        print('Done..')\n",
    "        \n",
    "        # prepare the data for seaborn         \n",
    "        print('Creating plot for this t-sne visualization..')\n",
    "        df = pd.DataFrame({'x':X_reduced[:,0], 'y':X_reduced[:,1] ,'label':y_data})\n",
    "        \n",
    "        # draw the plot in appropriate place in the grid\n",
    "        sns.lmplot(data=df, x='x', y='y', hue='label', fit_reg=False, size=8,\\\n",
    "                   palette=\"Set1\",markers=['^','v','s','o', '1','2'])\n",
    "        plt.title(\"perplexity : {} and max_iter : {}\".format(perplexity, n_iter))\n",
    "        img_name = img_name_prefix + '_perp_{}_iter_{}.png'.format(perplexity, n_iter)\n",
    "        print('saving this plot as image in present working directory...')\n",
    "        plt.savefig(img_name)\n",
    "        plt.show()\n",
    "        print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "wSEJzyasu06N",
    "outputId": "18172f54-afa8-4357-fb82-3762594ccb3e",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "X_pre_tsne = train.drop(['subject', 'Activity','ActivityName'], axis=1)\n",
    "y_pre_tsne = train['ActivityName']\n",
    "perform_tsne(X_data = X_pre_tsne,y_data=y_pre_tsne, perplexities =[2,5,10,20,50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "zfRPAckNu06O",
    "outputId": "f2a54b9f-ea0f-4648-f723-ed7406348051"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "X_pre_tsne = train.drop(['subject', 'Activity','ActivityName'], axis=1)\n",
    "y_pre_tsne = train['ActivityName']\n",
    "perform_tsne(X_data = X_pre_tsne,y_data=y_pre_tsne, perplexities =[20,50,90],n_iter=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vmurxLMfu06R"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3Q1wglS3u06S"
   },
   "source": [
    "## Obtain the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "uZ57kLI_u06S",
    "outputId": "e1c1aa9d-ca0b-43de-d9d0-e6a9b23864d5"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('/content/gdrive/My Drive/UCI HAR Dataset/UCI HAR Dataset/csv_files/train.csv')\n",
    "test = pd.read_csv('/content/gdrive/My Drive/UCI HAR Dataset/UCI HAR Dataset/csv_files/test.csv')\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "id": "3bYv5HuRu06U",
    "outputId": "f599c7d9-38fc-4e46-da80-0194fd4093e3"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ir1WUKtpu06X"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# get X_train and y_train from csv files\n",
    "X_train = train.drop(['subject', 'Activity', 'ActivityName'], axis=1)\n",
    "y_train = train.ActivityName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "enT51pjEu06Z"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# get X_test and y_test from test csv file\n",
    "X_test = test.drop(['subject', 'Activity', 'ActivityName'], axis=1)\n",
    "y_test = test.ActivityName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "TaXvyqVKu06b",
    "outputId": "05927ce9-93e4-43a4-8fe0-43d87cb51d05"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print('X_train and y_train : ({},{})'.format(X_train.shape, y_train.shape))\n",
    "print('X_test  and y_test  : ({},{})'.format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ECxq1J_Du06c"
   },
   "source": [
    "# Model with our data #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b2nPB0YAu06d"
   },
   "source": [
    "### Labels that are useful in plotting confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VSfCaYlQu06d"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "labels=['LAYING', 'SITTING','STANDING','WALKING','WALKING_DOWNSTAIRS','WALKING_UPSTAIRS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hvOkqiCLu06f"
   },
   "source": [
    "### Function to plot the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eEJvh7Y5u06f"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Xng0aVnu06h"
   },
   "source": [
    "### Generic function to run any model specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t2UTjqHqu06h"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "def perform_model(model, X_train, y_train, X_test, y_test, class_labels, cm_normalize=True, \\\n",
    "                 print_cm=True, cm_cmap=plt.cm.Greens):\n",
    "    \n",
    "    # to store results at various phases\n",
    "    results = dict()\n",
    "    \n",
    "    # time at which model starts training \n",
    "    train_start_time = datetime.now()\n",
    "    print('training the model..')\n",
    "    model.fit(X_train, y_train)\n",
    "    print('Done \\n \\n')\n",
    "    train_end_time = datetime.now()\n",
    "    results['training_time'] =  train_end_time - train_start_time\n",
    "    print('training_time(HH:MM:SS.ms) - {}\\n\\n'.format(results['training_time']))\n",
    "    \n",
    "    \n",
    "    # predict test data\n",
    "    print('Predicting test data')\n",
    "    test_start_time = datetime.now()\n",
    "    y_pred = model.predict(X_test)\n",
    "    test_end_time = datetime.now()\n",
    "    print('Done \\n \\n')\n",
    "    results['testing_time'] = test_end_time - test_start_time\n",
    "    print('testing time(HH:MM:SS:ms) - {}\\n\\n'.format(results['testing_time']))\n",
    "    results['predicted'] = y_pred\n",
    "   \n",
    "\n",
    "    # calculate overall accuracty of the model\n",
    "    accuracy = metrics.accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "    # store accuracy in results\n",
    "    results['accuracy'] = accuracy\n",
    "    print('---------------------')\n",
    "    print('|      Accuracy      |')\n",
    "    print('---------------------')\n",
    "    print('\\n    {}\\n\\n'.format(accuracy))\n",
    "    \n",
    "    \n",
    "    # confusion matrix\n",
    "    cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "    results['confusion_matrix'] = cm\n",
    "    if print_cm: \n",
    "        print('--------------------')\n",
    "        print('| Confusion Matrix |')\n",
    "        print('--------------------')\n",
    "        print('\\n {}'.format(cm))\n",
    "        \n",
    "    # plot confusin matrix\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.grid(b=False)\n",
    "    plot_confusion_matrix(cm, classes=class_labels, normalize=True, title='Normalized confusion matrix', cmap = cm_cmap)\n",
    "    plt.show()\n",
    "    \n",
    "    # get classification report\n",
    "    print('-------------------------')\n",
    "    print('| Classifiction Report |')\n",
    "    print('-------------------------')\n",
    "    classification_report = metrics.classification_report(y_test, y_pred)\n",
    "    # store report in results\n",
    "    results['classification_report'] = classification_report\n",
    "    print(classification_report)\n",
    "    \n",
    "    # add the trained  model to the results\n",
    "    results['model'] = model\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9H7dMbJsu06i"
   },
   "source": [
    "### Method to print the gridsearch Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oq6nTq3eu06j"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def print_grid_search_attributes(model):\n",
    "    # Estimator that gave highest score among all the estimators formed in GridSearch\n",
    "    print('--------------------------')\n",
    "    print('|      Best Estimator     |')\n",
    "    print('--------------------------')\n",
    "    print('\\n\\t{}\\n'.format(model.best_estimator_))\n",
    "\n",
    "\n",
    "    # parameters that gave best results while performing grid search\n",
    "    print('--------------------------')\n",
    "    print('|     Best parameters     |')\n",
    "    print('--------------------------')\n",
    "    print('\\tParameters of best estimator : \\n\\n\\t{}\\n'.format(model.best_params_))\n",
    "\n",
    "\n",
    "    #  number of cross validation splits\n",
    "    print('---------------------------------')\n",
    "    print('|   No of CrossValidation sets   |')\n",
    "    print('--------------------------------')\n",
    "    print('\\n\\tTotal numbre of cross validation sets: {}\\n'.format(model.n_splits_))\n",
    "\n",
    "\n",
    "    # Average cross validated score of the best estimator, from the Grid Search \n",
    "    print('--------------------------')\n",
    "    print('|        Best Score       |')\n",
    "    print('--------------------------')\n",
    "    print('\\n\\tAverage Cross Validate scores of best estimator : \\n\\n\\t{}\\n'.format(model.best_score_))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling with Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "abZ3Br7Eu06k"
   },
   "source": [
    "# 1. Logistic Regression with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AGgzXk6Ru06l"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "o8BppJRiu06n",
    "outputId": "0f18fadc-3e48-4eae-9bf0-f63ab1a9e10b"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# start Grid search\n",
    "parameters = {'C':[0.01, 0.1, 1, 10, 20, 30], 'penalty':['l2','l1']}\n",
    "log_reg = linear_model.LogisticRegression()\n",
    "log_reg_grid = GridSearchCV(log_reg, param_grid=parameters, cv=3, verbose=1, n_jobs=8)\n",
    "log_reg_grid_results =  perform_model(log_reg_grid, X_train, y_train, X_test, y_test, class_labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 576
    },
    "colab_type": "code",
    "id": "wU0eInFnu06p",
    "outputId": "4288729a-d151-4040-f3e6-b33440ed4aaf"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.grid(b=False)\n",
    "plot_confusion_matrix(log_reg_grid_results['confusion_matrix'], classes=labels, cmap=plt.cm.Greens, )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 555
    },
    "colab_type": "code",
    "id": "-wgrl4cNu06r",
    "outputId": "765441cc-2b7d-4a3a-dc7a-d471fdb4664d"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# observe the attributes of the model \n",
    "print_grid_search_attributes(log_reg_grid_results['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vCbj5BsPu06u"
   },
   "source": [
    "#  2. Linear SVC with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ju3l-tAJu06u"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "cjVveJk8u06v",
    "outputId": "8d16ae11-deb5-4ed8-bcee-8eba91ed81a8"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "parameters = {'C':[0.125, 0.5, 1, 2, 8, 16]}\n",
    "lr_svc = LinearSVC(tol=0.00005)\n",
    "lr_svc_grid = GridSearchCV(lr_svc, param_grid=parameters, n_jobs=8, verbose=1)\n",
    "lr_svc_grid_results = perform_model(lr_svc_grid, X_train, y_train, X_test, y_test, class_labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rGyp_91Wu06y",
    "outputId": "61acee94-2d63-45bd-dd21-d5a3d6d0edd2"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print_grid_search_attributes(lr_svc_grid_results['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "44SvlGKwu06z"
   },
   "source": [
    "# 3.  Kernel SVM with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qF9ByhWju060",
    "outputId": "9e954dfc-1ed9-4df9-f56c-1346f2c34714",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "parameters = {'C':[2,8,16],\\\n",
    "              'gamma': [ 0.0078125, 0.125, 2]}\n",
    "rbf_svm = SVC(kernel='rbf')\n",
    "rbf_svm_grid = GridSearchCV(rbf_svm,param_grid=parameters,n_jobs=8)\n",
    "rbf_svm_grid_results = perform_model(rbf_svm_grid, X_train, y_train, X_test, y_test, class_labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RtEtbTMhu062"
   },
   "source": [
    "# 4. Decision Trees with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rzSj--Lhu062",
    "outputId": "dad41c55-3351-4fc4-d82b-e0775e22e71c",
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "parameters = {'max_depth':np.arange(3,10,2)}\n",
    "dt = DecisionTreeClassifier()\n",
    "dt_grid = GridSearchCV(dt,param_grid=parameters, n_jobs=8)\n",
    "dt_grid_results = perform_model(dt_grid, X_train, y_train, X_test, y_test, class_labels=labels)\n",
    "print_grid_search_attributes(dt_grid_results['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PTUNYuUQu063"
   },
   "source": [
    "# 5. Random Forest Classifier with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8xk05PC0u064",
    "outputId": "6484090e-d479-402d-a8d9-9350c34c61ef"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "params = {'n_estimators': np.arange(10,201,20), 'max_depth':np.arange(3,15,2)}\n",
    "rfc = RandomForestClassifier()\n",
    "rfc_grid = GridSearchCV(rfc, param_grid=params, n_jobs=8)\n",
    "rfc_grid_results = perform_model(rfc_grid, X_train, y_train, X_test, y_test, class_labels=labels)\n",
    "print_grid_search_attributes(rfc_grid_results['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rVqgFXNLu066"
   },
   "source": [
    "# 6.  Gradient Boosted Decision Trees With GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7jjD3g7Eu066",
    "outputId": "013163ac-3c21-47b9-eac5-a7aeb30cea19"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "param_grid = {'max_depth': np.arange(5,8,1), \\\n",
    "             'n_estimators':np.arange(130,170,10)}\n",
    "gbdt = GradientBoostingClassifier()\n",
    "gbdt_grid = GridSearchCV(gbdt, param_grid=param_grid, n_jobs=8)\n",
    "gbdt_grid_results = perform_model(gbdt_grid, X_train, y_train, X_test, y_test, class_labels=labels)\n",
    "print_grid_search_attributes(gbdt_grid_results['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GaP20aZJu068"
   },
   "source": [
    "\n",
    "# 7. Comparing all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RN8GSsdTu068",
    "outputId": "fb10599f-a4cb-484d-f392-225416ab41b7"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print('\\n                     Accuracy     Error')\n",
    "print('                     ----------   --------')\n",
    "print('Logistic Regression : {:.04}%       {:.04}%'.format(log_reg_grid_results['accuracy'] * 100,\\\n",
    "                                                  100-(log_reg_grid_results['accuracy'] * 100)))\n",
    "\n",
    "print('Linear SVC          : {:.04}%       {:.04}% '.format(lr_svc_grid_results['accuracy'] * 100,\\\n",
    "                                                        100-(lr_svc_grid_results['accuracy'] * 100)))\n",
    "\n",
    "print('rbf SVM classifier  : {:.04}%      {:.04}% '.format(rbf_svm_grid_results['accuracy'] * 100,\\\n",
    "                                                          100-(rbf_svm_grid_results['accuracy'] * 100)))\n",
    "\n",
    "print('DecisionTree        : {:.04}%      {:.04}% '.format(dt_grid_results['accuracy'] * 100,\\\n",
    "                                                        100-(dt_grid_results['accuracy'] * 100)))\n",
    "\n",
    "print('Random Forest       : {:.04}%      {:.04}% '.format(rfc_grid_results['accuracy'] * 100,\\\n",
    "                                                           100-(rfc_grid_results['accuracy'] * 100)))\n",
    "print('GradientBoosting DT : {:.04}%      {:.04}% '.format(rfc_grid_results['accuracy'] * 100,\\\n",
    "                                                        100-(rfc_grid_results['accuracy'] * 100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Qz5oCvZu06-"
   },
   "source": [
    "# Using raw time series data and deep learning methods \n",
    "These are the following models:\n",
    "\n",
    "Model 1 - Using LSTM  \n",
    "Model 2 - Using CNN \n",
    "\n",
    "Model 3 - PSO Optimized CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MVFOcs0Vu06_"
   },
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "1c5NdMEJu06_",
    "outputId": "96993e72-ea1f-4419-8eaa-1641eb4feaf2"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mYTeXEq_u07D"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Activities are the class labels\n",
    "# It is a 6 class classification\n",
    "ACTIVITIES = {\n",
    "    0: 'WALKING',\n",
    "    1: 'WALKING_UPSTAIRS',\n",
    "    2: 'WALKING_DOWNSTAIRS',\n",
    "    3: 'SITTING',\n",
    "    4: 'STANDING',\n",
    "    5: 'LAYING',\n",
    "}\n",
    "\n",
    "# Utility function to print the confusion matrix\n",
    "def confusion_matrix(Y_true, Y_pred):\n",
    "    Y_true = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_true, axis=1)])\n",
    "    Y_pred = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_pred, axis=1)])\n",
    "\n",
    "    return pd.crosstab(Y_true, Y_pred, rownames=['True'], colnames=['Pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l5KdDj-Au07E"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Data directory\n",
    "DATADIR = '/content/gdrive/My Drive/UCI HAR Dataset/UCI HAR Dataset'\n",
    "# Raw data signals\n",
    "# Signals are from Accelerometer and Gyroscope\n",
    "# The signals are in x,y,z directions\n",
    "# Sensor signals are filtered to have only body acceleration\n",
    "# excluding the acceleration due to gravity\n",
    "# Triaxial acceleration from the accelerometer is total acceleration\n",
    "SIGNALS = [\n",
    "    \"body_acc_x\",\n",
    "    \"body_acc_y\",\n",
    "    \"body_acc_z\",\n",
    "    \"body_gyro_x\",\n",
    "    \"body_gyro_y\",\n",
    "    \"body_gyro_z\",\n",
    "    \"total_acc_x\",\n",
    "    \"total_acc_y\",\n",
    "    \"total_acc_z\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JnNTK8yuu07H"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Utility function to read the data from csv file\n",
    "def _read_csv(filename):\n",
    "    return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
    "\n",
    "# Utility function to load the load\n",
    "def load_signals(subset):\n",
    "    signals_data = []\n",
    "\n",
    "    for signal in SIGNALS:\n",
    "        filename = f'/content/gdrive/My Drive/UCI HAR Dataset/UCI HAR Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
    "        signals_data.append(\n",
    "            _read_csv(filename).as_matrix()\n",
    "        ) \n",
    "\n",
    "    # Transpose is used to change the dimensionality of the output,\n",
    "    # aggregating the signals by combination of sample/timestep.\n",
    "    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
    "    return np.transpose(signals_data, (1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nQoweDtdu07I"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "def load_y(subset):\n",
    "    \"\"\"\n",
    "    The objective that we are trying to predict is a integer, from 1 to 6,\n",
    "    that represents a human activity. We return a binary representation of \n",
    "    every sample objective as a 6 bits vector using One Hot Encoding\n",
    "    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
    "    \"\"\"\n",
    "    filename = f'/content/gdrive/My Drive/UCI HAR Dataset/UCI HAR Dataset/{subset}/y_{subset}.txt'\n",
    "    y = _read_csv(filename)[0]\n",
    "\n",
    "    return pd.get_dummies(y).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3FPpCC8nu07K"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    Obtain the dataset from multiple files.\n",
    "    Returns: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    X_train, X_test = load_signals('train'), load_signals('test')\n",
    "    y_train, y_test = load_y('train'), load_y('test')\n",
    "\n",
    "    return X_train, y_train, X_test,  y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 322
    },
    "colab_type": "code",
    "id": "PxXxHUcju07L",
    "outputId": "92e40e87-34eb-4ac3-d4be-f600d975448a"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Importing tensorflow\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "#tf.random.set_seed(36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "VwDwESfhu07M",
    "outputId": "330e5672-957e-4248-de19-e9dd028cf744"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "grlfvvm_8WQt",
    "outputId": "9b75fc20-a142-4e8a-9eb8-10991f8249c1"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "pip install keras==2.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FCVc8Uw_u07O"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Initializing parameters\n",
    "epochs = 30\n",
    "batch_size = 16\n",
    "n_hidden = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0T9T8nXZu07P"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Utility function to count the number of classes\n",
    "def _count_classes(y):\n",
    "    return len(set([tuple(category) for category in y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "45OIcaV-u07R"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Loading the train and test data\n",
    "X_train, Y_train, X_test,  Y_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "wZ04nExd9Qc1",
    "outputId": "c670646a-b9ec-4116-8b04-5c49890c9c69"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "X_train.shape,Y_train.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "tK7JJyLDu07T",
    "outputId": "868bcf7d-48bf-484e-f66e-28247d092da6"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = _count_classes(Y_train)\n",
    "#n_classes  = 6\n",
    "print(timesteps)\n",
    "print(input_dim)\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GNW0Tkn7u07U"
   },
   "source": [
    "#### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "colab_type": "code",
    "id": "y2ojkdPVu07U",
    "outputId": "3c9b42c5-6c6b-4c89-8c3e-504924e69c02"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6WtMAtpsu07W"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "-ozwUsdVu07X",
    "outputId": "1cc39671-64b0-4ea3-d7e5-e7637524d7c0"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_htfOKQCu07Y"
   },
   "source": [
    "#### Multi layer LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "colab_type": "code",
    "id": "N7GkRhDVu07Y",
    "outputId": "27137bf8-dab8-46ec-f65a-61070e22c609"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(32,return_sequences=True,input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(LSTM(28,input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.6))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6-1WwfdVu07Z"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "gLndow1Fu07a",
    "outputId": "6ca45c32-ec88-491c-8dfc-2df0e1633fed"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fJRzTVbBu07d"
   },
   "source": [
    "Above 2 layer LSTM is giving similar score as 1 layer LSTM which we trained above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dtWMpuMeu07d"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "colab_type": "code",
    "id": "brRbj5Nyu07e",
    "outputId": "4bee6e01-69e5-4dc7-ba16-434196e84402"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(32,recurrent_regularizer=l2(0.003),return_sequences=True,input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(LSTM(28,input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.6))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "En4KMEE6u07f"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rm9AR9__u07g",
    "outputId": "6e5c1f52-9c37-4445-a2d1-13e645c53ac6"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "History = model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ssy0lC9ju07h"
   },
   "source": [
    "### Hyperparameter Tuning Using Hyperas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "syiywPy5u07i"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Importing tensorflow\n",
    "np.random.seed(36)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zdVdNGQ5u07j"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "from hyperas.utils import eval_hyperopt_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "hVX8RjRFT7le",
    "outputId": "3b759d2a-276f-4b47-d62a-8e05f4c095e8"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "pip install hyperas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gi7fWmYsu07k"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "##gives train and validation data \n",
    "def data():\n",
    "    \"\"\"\n",
    "    Obtain the dataset from multiple files.\n",
    "    Returns: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    # Data directory\n",
    "    DATADIR = '/content/gdrive/My Drive/UCI HAR Dataset/UCI HAR Dataset/'\n",
    "    # Raw data signals\n",
    "    # Signals are from Accelerometer and Gyroscope\n",
    "    # The signals are in x,y,z directions\n",
    "    # Sensor signals are filtered to have only body acceleration\n",
    "    # excluding the acceleration due to gravity\n",
    "    # Triaxial acceleration from the accelerometer is total acceleration\n",
    "    SIGNALS = [\n",
    "        \"body_acc_x\",\n",
    "        \"body_acc_y\",\n",
    "        \"body_acc_z\",\n",
    "        \"body_gyro_x\",\n",
    "        \"body_gyro_y\",\n",
    "        \"body_gyro_z\",\n",
    "        \"total_acc_x\",\n",
    "        \"total_acc_y\",\n",
    "        \"total_acc_z\"\n",
    "        ]\n",
    "    # Utility function to read the data from csv file\n",
    "    def _read_csv(filename):\n",
    "        return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
    "\n",
    "    # Utility function to load the load\n",
    "    def load_signals(subset):\n",
    "        signals_data = []\n",
    "\n",
    "        for signal in SIGNALS:\n",
    "            filename = f'/content/gdrive/My Drive/UCI HAR Dataset/UCI HAR Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
    "            signals_data.append( _read_csv(filename).as_matrix()) \n",
    "\n",
    "        # Transpose is used to change the dimensionality of the output,\n",
    "        # aggregating the signals by combination of sample/timestep.\n",
    "        # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
    "        return np.transpose(signals_data, (1, 2, 0))\n",
    "    \n",
    "    def load_y(subset):\n",
    "        \"\"\"\n",
    "        The objective that we are trying to predict is a integer, from 1 to 6,\n",
    "        that represents a human activity. We return a binary representation of \n",
    "        every sample objective as a 6 bits vector using One Hot Encoding\n",
    "        (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
    "        \"\"\"\n",
    "        filename = f'/content/gdrive/My Drive/UCI HAR Dataset/UCI HAR Dataset/{subset}/y_{subset}.txt'\n",
    "        y = _read_csv(filename)[0]\n",
    "        return pd.get_dummies(y).as_matrix()\n",
    "    \n",
    "    X_train, X_val = load_signals('train'), load_signals('test')\n",
    "    Y_train, Y_val = load_y('train'), load_y('test')\n",
    "\n",
    "    return X_train, Y_train, X_val,  Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_M5zoJMIu07l"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from keras.regularizers import l2\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bdi7dl9Eu07m"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "##model\n",
    "def model(X_train, Y_train, X_val, Y_val):\n",
    "    # Importing tensorflow\n",
    "    np.random.seed(36)\n",
    "    import tensorflow as tf\n",
    "    tf.random.set_seed(36)\n",
    "    # Initiliazing the sequential model\n",
    "    model = Sequential() \n",
    "    if conditional({{choice(['one', 'two'])}}) == 'two':\n",
    "        # Configuring the parameters\n",
    "        model.add(LSTM({{choice([28,32,38])}},recurrent_regularizer=l2({{uniform(0,0.0002)}}),return_sequences=True,input_shape=(128, 9),name='LSTM2_1'))\n",
    "        # Adding a dropout layer\n",
    "        model.add(Dropout({{uniform(0.35,0.65)}},name='Dropout2_1'))\n",
    "        model.add(LSTM({{choice([26,32,36])}},recurrent_regularizer=l2({{uniform(0,0.001)}}),input_shape=(128, 9),name='LSTM2_2'))\n",
    "        model.add(Dropout({{uniform(0.5,0.7)}},name='Dropout2_2'))\n",
    "        # Adding a dense output layer with sigmoid activation\n",
    "        model.add(Dense(6, activation='sigmoid'))\n",
    "    else:\n",
    "        # Configuring the parameters\n",
    "        model.add(LSTM({{choice([28,32,36])}},recurrent_regularizer=l2({{uniform(0,0.001)}}),input_shape=(128, 9),name='LSTM1_1'))\n",
    "        # Adding a dropout layer\n",
    "        model.add(Dropout({{uniform(0.35,0.55)}},name='Dropout1_1'))\n",
    "        # Adding a dense output layer with sigmoid activation\n",
    "        model.add(Dense(6, activation='sigmoid'))\n",
    "        \n",
    "    adam = keras.optimizers.Adam(lr={{uniform(0.009,0.025)}})\n",
    "    rmsprop = keras.optimizers.RMSprop(lr={{uniform(0.009,0.025)}})\n",
    "   \n",
    "    choiceval = {{choice(['adam', 'rmsprop'])}}\n",
    "    \n",
    "    if choiceval == 'adam':\n",
    "        optim = adam\n",
    "    else:\n",
    "        optim = rmsprop\n",
    "    \n",
    "    print(model.summary())\n",
    "        \n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer=optim)\n",
    "    \n",
    "    result = model.fit(X_train, Y_train,\n",
    "              batch_size=16,\n",
    "              epochs=30,\n",
    "              verbose=2,\n",
    "              validation_data=(X_val, Y_val))\n",
    "                       \n",
    "    score, acc = model.evaluate(X_val, Y_val, verbose=0)\n",
    "    print('Test accuracy:', acc)\n",
    "    print('-------------------------------------------------------------------------------------')\n",
    "    return {'loss': -acc, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "colab_type": "code",
    "id": "rMOnJH2tu07n",
    "outputId": "72b4d9ce-c6c6-46e4-9eda-98f9843cde73",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_val, Y_val = data()\n",
    "trials = Trials()\n",
    "best_run, best_model, space = optim.minimize(model=model,\n",
    "                                      data=data,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=15,\n",
    "                                      trials=trials,notebook_name = 'Human Activity Detection',\n",
    "                                     return_space = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mdN1MRwmu07o",
    "outputId": "a9948ea2-abe1-4695-93b9-8afa97cc7340"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "total_trials = dict()\n",
    "for t, trial in enumerate(trials):\n",
    "        vals = trial.get('misc').get('vals')\n",
    "        print('Model',t+1,'parameters')\n",
    "        print(vals)\n",
    "        print()\n",
    "        z = eval_hyperopt_space(space, vals)\n",
    "        total_trials['M'+str(t+1)] = z\n",
    "        print(z)\n",
    "        print('------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kDm7h0UXu07r",
    "outputId": "c5334995-dbdf-49e9-e7cd-ba0dc010b9d0"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "best_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EnFteQmTu07s",
    "outputId": "d62f2c58-49cb-42a7-ee76-ce41c746765d"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#BEST MODEL PARAMS\n",
    "total_trials['M14']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lSemkgUFu07t",
    "outputId": "42d84aaa-7b3b-4322-e62f-7f9150933a51"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#layes of best model\n",
    "best_model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ce33Sjlcu07w"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_val, Y_val = data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fc1h8gq7u07x",
    "outputId": "c8f07fe3-3e82-4de0-ce0d-992a319d7750"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "_,val_acc = best_model.evaluate(X_val, Y_val, verbose=0)\n",
    "_,train_acc = best_model.evaluate(X_train, Y_train, verbose=0)\n",
    "print('Train_accuracy',val_acc)\n",
    "print('validation accuracy',val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qC-FebMru07z"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Activities are the class labels\n",
    "# It is a 6 class classification\n",
    "ACTIVITIES = {\n",
    "    0: 'WALKING',\n",
    "    1: 'WALKING_UPSTAIRS',\n",
    "    2: 'WALKING_DOWNSTAIRS',\n",
    "    3: 'SITTING',\n",
    "    4: 'STANDING',\n",
    "    5: 'LAYING',\n",
    "}\n",
    "\n",
    "# Utility function to print the confusion matrix\n",
    "def confusion_matrix_rnn(Y_true, Y_pred):\n",
    "    Y_true = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_true, axis=1)])\n",
    "    Y_pred = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_pred, axis=1)])\n",
    "\n",
    "    #return pd.crosstab(Y_true, Y_pred, rownames=['True'], colnames=['Pred'])\n",
    "    return metrics.confusion_matrix(Y_true, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jt2uYXHcu07z",
    "outputId": "6f288c87-c2e2-4ed7-e7bc-2cb689c13c07"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix_rnn(Y_val, best_model.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TH6W68ngu071"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QYqwHC0Ru072",
    "outputId": "bb213ee8-5bb9-4df9-bde9-32b1492a0f7a"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "cm = confusion_matrix_rnn(Y_val, best_model.predict(X_val))\n",
    "plot_confusion_matrix(cm, classes=labels, normalize=True, title='Normalized confusion matrix', cmap = plt.cm.Greens)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gVezacVNu073"
   },
   "source": [
    "## Using CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YWi8a13Lu073"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "np.random.seed(36)\n",
    "rn.seed(36)\n",
    "#tf.random.set_seed(36)\n",
    "# Force TensorFlow to use single thread.\n",
    "# Multiple threads are a potential source of non-reproducible results.\n",
    "# For further details, see: https://stackoverflow.com/questions/42022950/\n",
    "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
    "                              inter_op_parallelism_threads=1)\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "# The below tf.set_random_seed() will make random number generation\n",
    "# in the TensorFlow backend have a well-defined initial state.\n",
    "# For further details, see:\n",
    "# https://www.tensorflow.org/api_docs/python/tf/set_random_seed\n",
    "\n",
    "#tf.set_random_seed(36)\n",
    "#tf.random.set_seed(36)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gg4TTVYHu074"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9BkdbgKiu075"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_val, Y_val = data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "HnCQqAdXOl2i",
    "outputId": "099a5417-d925-417b-afae-c4e01b7641cf"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "X_train.shape, Y_train.shape, X_val.shape, Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "A9ndQ6UM4ym6",
    "outputId": "046b94fb-5479-46f0-8fbc-93b9d00fc4b2"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "X_train.shape,Y_train.shape,X_val.shape, Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "plnDFxRzu076"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "###Scling data\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class scaling_tseries_data(BaseEstimator, TransformerMixin):\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    def __init__(self):\n",
    "        self.scale = None\n",
    "\n",
    "    def transform(self, X):\n",
    "        temp_X1 = X.reshape((X.shape[0] * X.shape[1], X.shape[2]))\n",
    "        temp_X1 = self.scale.transform(temp_X1)\n",
    "        return temp_X1.reshape(X.shape)\n",
    "\n",
    "    def fit(self, X):\n",
    "        # remove overlaping\n",
    "        remove = int(X.shape[1] / 2)\n",
    "        temp_X = X[:, -remove:, :]\n",
    "        # flatten data\n",
    "        temp_X = temp_X.reshape((temp_X.shape[0] * temp_X.shape[1], temp_X.shape[2]))\n",
    "        scale = StandardScaler()\n",
    "        scale.fit(temp_X)\n",
    "        self.scale = scale\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t3JTTOubu077"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "Scale = scaling_tseries_data()\n",
    "Scale.fit(X_train)\n",
    "X_train_sc = Scale.transform(X_train)\n",
    "X_val_sc = Scale.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "rU5NKm09u079",
    "outputId": "d7d9dd63-e9b0-48b7-ef96-70cc842757e9"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print('Shape of scaled X train',X_train_sc.shape)\n",
    "print('Shape of scaled X test',X_val_sc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0CRs5UGtu07-"
   },
   "source": [
    "#### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "colab_type": "code",
    "id": "SqquBHA1u07-",
    "outputId": "086e5b96-65ac-4af7-a025-35e606bbd8b3"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu',kernel_initializer='he_uniform',input_shape=(128,9)))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu',kernel_initializer='he_uniform'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pePrZH7Qu08A"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Cs2jNDjvu08B",
    "outputId": "4a916a96-fa83-40df-9680-ae99737293cc",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model.fit(X_train_sc,Y_train, epochs=30, batch_size=16,validation_data=(X_val_sc, Y_val), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ul0j2zUOu08C"
   },
   "source": [
    "it is giving some good score in train as well as test but it is overfitting so much. i will try some regularization in below models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FdEBIikmu08C"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from keras.regularizers import l2,l1\n",
    "import keras\n",
    "from keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "colab_type": "code",
    "id": "Qo3XwDBYu08D",
    "outputId": "0f421529-39d4-43a9-a538-eb5f7eefb809"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu',kernel_initializer='he_uniform',\n",
    "                 kernel_regularizer=l2(0.1),input_shape=(128,9)))\n",
    "model.add(Conv1D(filters=16, kernel_size=3, activation='relu',kernel_regularizer=l2(0.06),kernel_initializer='he_uniform'))\n",
    "model.add(Dropout(0.65))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y2cvZYh4u08E"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import math\n",
    "adam = keras.optimizers.Adam(lr=0.001)\n",
    "rmsprop = keras.optimizers.RMSprop(lr=0.001)\n",
    "def step_decay(epoch):\n",
    "    return float(0.001 * math.pow(0.6, math.floor((1+epoch)/10)))\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "callbacks_list = [lrate]\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "uVA4yPHdu08F",
    "outputId": "59888e9d-49b3-48ae-ec14-19449e48b19d",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model.fit(X_train_sc,Y_train, epochs=30, batch_size=16,validation_data=(X_val_sc, Y_val), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pHlQ0HSNu08G"
   },
   "source": [
    "#### Hyper Parameter Tuning Using Hyperas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DoIYzn8Lu08G"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def data_scaled():\n",
    "    \"\"\"\n",
    "    Obtain the dataset from multiple files.\n",
    "    Returns: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    # Data directory\n",
    "    DATADIR = '/content/gdrive/My Drive/UCI HAR Dataset/UCI HAR Dataset'\n",
    "    # Raw data signals\n",
    "    # Signals are from Accelerometer and Gyroscope\n",
    "    # The signals are in x,y,z directions\n",
    "    # Sensor signals are filtered to have only body acceleration\n",
    "    # excluding the acceleration due to gravity\n",
    "    # Triaxial acceleration from the accelerometer is total acceleration\n",
    "    SIGNALS = [\n",
    "        \"body_acc_x\",\n",
    "        \"body_acc_y\",\n",
    "        \"body_acc_z\",\n",
    "        \"body_gyro_x\",\n",
    "        \"body_gyro_y\",\n",
    "        \"body_gyro_z\",\n",
    "        \"total_acc_x\",\n",
    "        \"total_acc_y\",\n",
    "        \"total_acc_z\"\n",
    "        ]\n",
    "    from sklearn.base import BaseEstimator, TransformerMixin\n",
    "    class scaling_tseries_data(BaseEstimator, TransformerMixin):\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        def __init__(self):\n",
    "            self.scale = None\n",
    "\n",
    "        def transform(self, X):\n",
    "            temp_X1 = X.reshape((X.shape[0] * X.shape[1], X.shape[2]))\n",
    "            temp_X1 = self.scale.transform(temp_X1)\n",
    "            return temp_X1.reshape(X.shape)\n",
    "\n",
    "        def fit(self, X):\n",
    "            # remove overlaping\n",
    "            remove = int(X.shape[1] / 2)\n",
    "            temp_X = X[:, -remove:, :]\n",
    "            # flatten data\n",
    "            temp_X = temp_X.reshape((temp_X.shape[0] * temp_X.shape[1], temp_X.shape[2]))\n",
    "            scale = StandardScaler()\n",
    "            scale.fit(temp_X)\n",
    "            self.scale = scale\n",
    "            return self\n",
    "        \n",
    "    # Utility function to read the data from csv file\n",
    "    def _read_csv(filename):\n",
    "        return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
    "\n",
    "    # Utility function to load the load\n",
    "    def load_signals(subset):\n",
    "        signals_data = []\n",
    "\n",
    "        for signal in SIGNALS:\n",
    "            filename = f'/content/gdrive/My Drive/UCI HAR Dataset/UCI HAR Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
    "            signals_data.append( _read_csv(filename).as_matrix()) \n",
    "\n",
    "        # Transpose is used to change the dimensionality of the output,\n",
    "        # aggregating the signals by combination of sample/timestep.\n",
    "        # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
    "        return np.transpose(signals_data, (1, 2, 0))\n",
    "    \n",
    "    def load_y(subset):\n",
    "        \"\"\"\n",
    "        The objective that we are trying to predict is a integer, from 1 to 6,\n",
    "        that represents a human activity. We return a binary representation of \n",
    "        every sample objective as a 6 bits vector using One Hot Encoding\n",
    "        (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
    "        \"\"\"\n",
    "        filename = f'/content/gdrive/My Drive/UCI HAR Dataset/UCI HAR Dataset/{subset}/y_{subset}.txt'\n",
    "        y = _read_csv(filename)[0]\n",
    "        return pd.get_dummies(y).as_matrix()\n",
    "    \n",
    "    X_train, X_val = load_signals('train'), load_signals('test')\n",
    "    Y_train, Y_val = load_y('train'), load_y('test')\n",
    "    ###Scling data\n",
    "    Scale = scaling_tseries_data()\n",
    "    Scale.fit(X_train)\n",
    "    X_train = Scale.transform(X_train)\n",
    "    X_val = Scale.transform(X_val)\n",
    "\n",
    "    return X_train, Y_train, X_val,  Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KSc8LGRmu08H"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_val,  Y_val = data_scaled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "fWdrHs5SO6pG",
    "outputId": "66977ca1-b4c6-4d0d-9455-ed05d7b0bfa0"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "X_train.shape,Y_train.shape, X_val.shape, Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DgSiIYz6u08I"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def model_cnn(X_train, Y_train, X_val, Y_val):\n",
    "    # Importing tensorflow\n",
    "    np.random.seed(36)\n",
    "    import tensorflow as tf\n",
    "    tf.random.set_seed(36)\n",
    "    # Initiliazing the sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv1D(filters={{choice([28,32,42])}}, kernel_size={{choice([3,5,7])}},activation='relu',kernel_initializer='he_uniform',\n",
    "                 kernel_regularizer=l2({{uniform(0,2.5)}}),input_shape=(128,9)))\n",
    "    \n",
    "    model.add(Conv1D(filters={{choice([16,24,32])}}, kernel_size={{choice([3,5,7])}}, \n",
    "                     activation='relu',kernel_regularizer=l2({{uniform(0,1.5)}}),kernel_initializer='he_uniform'))\n",
    "    model.add(Dropout({{uniform(0.45,0.7)}}))\n",
    "    model.add(MaxPooling1D(pool_size={{choice([2,3])}}))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense({{choice([32,64])}}, activation='relu'))\n",
    "    model.add(Dense(6, activation='softmax'))\n",
    "        \n",
    "    adam = keras.optimizers.Adam(lr={{uniform(0.00065,0.004)}})\n",
    "    rmsprop = keras.optimizers.RMSprop(lr={{uniform(0.00065,0.004)}})\n",
    "   \n",
    "    choiceval = {{choice(['adam', 'rmsprop'])}}\n",
    "    \n",
    "    if choiceval == 'adam':\n",
    "        optim = adam\n",
    "    else:\n",
    "        optim = rmsprop\n",
    "    \n",
    "    print(model.summary())\n",
    "        \n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer=optim)\n",
    "    \n",
    "    result = model.fit(X_train, Y_train,\n",
    "              batch_size={{choice([16,32,64])}},\n",
    "              epochs={{choice([25,30,35])}},\n",
    "              verbose=2,\n",
    "              validation_data=(X_val, Y_val))\n",
    "                       \n",
    "    score, acc = model.evaluate(X_val, Y_val, verbose=0)\n",
    "    score1, acc1 = model.evaluate(X_train, Y_train, verbose=0)\n",
    "    print('Train accuracy',acc1,'Test accuracy:', acc)\n",
    "    print('-------------------------------------------------------------------------------------')\n",
    "    return {'loss': -acc, 'status': STATUS_OK, 'model': model,'train_acc':acc1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SPoOf1Ga4c1z"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "yCIkjY-Du08J",
    "outputId": "c50c4b12-a4ed-45c2-c245-54c7e247d6d8"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_val, Y_val = data_scaled()\n",
    "trials = Trials()\n",
    "best_run, best_model, space = optim.minimize(model=model_cnn,\n",
    "                                      data=data_scaled,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=100,\n",
    "                                      trials=trials,notebook_name = 'Human Activity Detection-Without Verbose ',\n",
    "                                      return_space = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mfg2aujEu08K"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from hyperas.utils import eval_hyperopt_space\n",
    "total_trials = dict()\n",
    "total_list = []\n",
    "for t, trial in enumerate(trials):\n",
    "        vals = trial.get('misc').get('vals')\n",
    "        z = eval_hyperopt_space(space, vals)\n",
    "        total_trials['M'+str(t+1)] = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EnJWwGp7u08L",
    "outputId": "7eb9b913-601f-43e1-ebe9-c1dd11103efe"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "best_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F27UC02Tu08N",
    "outputId": "1a1f4505-49e4-4dd4-de04-e292b70f84c5"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#best Hyper params from hyperas\n",
    "eval_hyperopt_space(space, best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W0kN8mbku08Q",
    "outputId": "b83e4329-407b-48d3-d348-2c705749f14c"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Pw_nCeWu08R",
    "outputId": "409bc9f3-c359-466a-95e4-c9808b9a833d"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "_,acc_val = best_model.evaluate(X_val,Y_val,verbose=0)\n",
    "_,acc_train = best_model.evaluate(X_train,Y_train,verbose=0)\n",
    "print('Train_accuracy',acc_train,'test_accuracy',acc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0PiCijyCu08S",
    "outputId": "0ad8e789-2b35-41c5-efab-9375611c2655"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix_rnn(Y_val, best_model.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kjKiyLoyu08T",
    "outputId": "0a98cc32-280c-4739-f1b6-9c8707c3ab38"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8,8))\n",
    "cm = confusion_matrix_rnn(Y_val, best_model.predict(X_val))\n",
    "plot_confusion_matrix(cm, classes=labels, normalize=True, title='Normalized confusion matrix', cmap = plt.cm.Greens)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wAtu_qjxl6_U"
   },
   "source": [
    "# **`PSO OPTIMIZED CNN `**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NKSXc-RumPy2"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "from keras import optimizers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "THxQmDqaPNTG"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "X_val,Y_val\n",
    "X_train,Y_train,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FiDovOn6BYEZ"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/content/gdrive/My Drive/Hyperactive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_kcpZc2cpxOh"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#import hyperactive\n",
    "import sklearn.externals\n",
    "import joblib\n",
    "#from hyperactive.Hyperactive import ParticleSwarmOptimizer\n",
    "#from hyperactive import ParticleSwarmOptimizer\n",
    "from hyperactive import RandomSearchOptimizer, ParticleSwarmOptimizer\n",
    "\n",
    "#import RandomSearchOptimizer, ParticleSwarmOptimizer\n",
    "#from hyperactive import ParticleSwarmOptimizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r0hjU4F6p2W5"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Activation, Dropout\n",
    "from keras.layers import Dense, Conv21D, MaxPooling1D, Flatten, Activation, Dropout\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tQmriD8Zp8hk"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype('float32')/255.0\n",
    "X_test = X_test.astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "njSPFXzOp-mS"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xM0TwnGxqA0D"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "sgd = optimizers.SGD(lr=0.01)\n",
    "adam = optimizers.Adam(lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kz-rtJWCqDeP"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "search_config = {\n",
    "    \"keras.compile.0\": {\"loss\": [\"categorical_crossentropy\"], \"optimizer\": [adam, sgd]},\n",
    "    \"keras.fit.0\": {\"epochs\": [10], \"batch_size\": range(10, 101), \"verbose\": [2]},\n",
    "    \"keras.layers.Conv1D.1\": {\n",
    "        \"filters\": range(4, 101),\n",
    "        \"kernel_size\": [3, 5, 7],\n",
    "        \"activation\": [\"sigmoid\", \"relu\", \"tanh\"],\n",
    "        \"input_shape\": [(128,9)],\n",
    "    },\n",
    "    \"keras.layers.MaxPooling1D.2\": {\"pool_size\": [(2)]},\n",
    "    \"keras.layers.Conv1D.3\": {\n",
    "        \"filters\": range(4, 101),\n",
    "        \"kernel_size\": [3, 5, 7],\n",
    "        \"activation\": [\"sigmoid\", \"relu\", \"tanh\"],\n",
    "    },\n",
    "    \"keras.layers.MaxPooling1D.4\": {\"pool_size\": [(2)]},\n",
    "    \"keras.layers.Flatten.5\": {},\n",
    "    \"keras.layers.Dense.6\": {\"units\": range(4, 201), \"activation\": [\"sigmoid\", \"relu\", \"tanh\"]},\n",
    "    \"keras.layers.Dense.7\": {\"units\": range(4, 201), \"activation\": [\"sigmoid\", \"relu\", \"tanh\"]},\n",
    "    #\"keras.layers.Dropout.7\": {\"rate\": list(np.arange(0.2, 0.8, 0.2))},\n",
    "    \"keras.layers.Dense.8\": {\"units\": [6], \"activation\": [\"softmax\"]},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H-szuysQqFxN"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "Optimizer = ParticleSwarmOptimizer(search_config, n_iter=10, n_part=10, metric='accuracy', cv=0.8, w=0.7, c_k=2.0, c_s=2.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "K8e8-3zeqH9b",
    "outputId": "70e26bec-7bbd-40cb-f1e2-b92572d3fe92"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "Optimizer.fit(X_train, Y_train)\n",
    "t2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "vRp_3zaCqK2Y",
    "outputId": "5045f98b-2b49-4230-eb4f-7008e286c083"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(\"time: {}\".format(t2-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "And1e2rgqNsL",
    "outputId": "ebd7fb24-5826-4110-d787-7b4cd1afdafb"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "Optimizer.predict(X_val)\n",
    "score = Optimizer.score(X_val, Y_val)\n",
    "print(\"test score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-hvl-WdaXWzz"
   },
   "source": [
    "**PSO WITH MAIN.py file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "HrDcNpm4Xelb",
    "outputId": "2ce3b0f8-54c3-4ef6-8679-5fdb736c8371"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "HTQ7OaxA0qAm",
    "outputId": "7a7f743c-e333-45ea-f388-86afa0edd54d"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "8J0eOthDiUB0",
    "outputId": "6582a227-030c-49df-d657-9fe827329ad9"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import keras\n",
    "#from psoCNN import psoCNN\n",
    "import numpy as np\n",
    "import time\n",
    "import keras.backend\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() \n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_hub as hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jbbgaNSg2WIh"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "########################## POPULATION FILE ###################################################\n",
    "#from particle import Particle\n",
    "\n",
    "class Population:\n",
    "    def __init__(self, pop_size, min_layer, max_layer, input_width, input_channels, conv_prob, pool_prob, fc_prob, max_conv_kernel, max_out_ch, max_fc_neurons, output_dim):\n",
    "        # Compute maximum number of pooling layers for any given particle\n",
    "        print('*************** population file **************************')\n",
    "        max_pool_layers = 0\n",
    "        in_w = input_width\n",
    "\n",
    "        while in_w > 4:\n",
    "            max_pool_layers += 1\n",
    "            in_w = in_w/2\n",
    "\n",
    "        self.particle = []\n",
    "        for i in range(pop_size):\n",
    "            self.particle.append(Particle(min_layer, max_layer, max_pool_layers, input_width, input_channels, conv_prob, pool_prob, fc_prob, max_conv_kernel, max_out_ch, max_fc_neurons, output_dim))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KNmovjtl2Fn5"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "######################### PARTICLE FILE ########################################\n",
    "import utils\n",
    "\n",
    "import keras.backend\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Add, Dense, Dropout, Flatten\n",
    "from keras.layers import Activation, Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import Activation, Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras import regularizers \n",
    "from keras.optimizers import Adam, Nadam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# Hide Tensorflow INFOS and WARNINGS\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "\n",
    "class Particle:\n",
    "    def __init__(self, min_layer, max_layer, max_pool_layers, input_width, input_channels, \\\n",
    "        conv_prob, pool_prob, fc_prob, max_conv_kernel, max_out_ch, max_fc_neurons, output_dim):\n",
    "        self.input_width = input_width\n",
    "        #self.input_height = input_height\n",
    "        self.input_channels = input_channels\n",
    "        print('*************** particle file after edit**************************')\n",
    "\n",
    "\n",
    "        self.num_pool_layers = 0\n",
    "        self.max_pool_layers = max_pool_layers\n",
    "\n",
    "        self.feature_width = input_width\n",
    "        #self.feature_height = input_height\n",
    "\n",
    "        self.depth = np.random.randint(min_layer, max_layer)\n",
    "        self.conv_prob = conv_prob\n",
    "        self.pool_prob = pool_prob\n",
    "        self.fc_prob = fc_prob\n",
    "        self.max_conv_kernel = max_conv_kernel\n",
    "        self.max_out_ch = max_out_ch\n",
    "        \n",
    "        self.max_fc_neurons = max_fc_neurons\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.layers = []\n",
    "        self.acc = None\n",
    "        self.vel = [] # Initial velocity\n",
    "        self.pBest = []\n",
    "\n",
    "        # Build particle architecture\n",
    "        self.initialization()\n",
    "        \n",
    "        # Update initial velocity\n",
    "        for i in range(len(self.layers)):\n",
    "            if self.layers[i][\"type\"] != \"fc\":\n",
    "                self.vel.append({\"type\": \"keep\"})\n",
    "            else:\n",
    "                self.vel.append({\"type\": \"keep_fc\"})\n",
    "        \n",
    "        self.model = None\n",
    "        self.pBest = deepcopy(self)\n",
    "\n",
    "    \n",
    "    def __str__(self):\n",
    "        string = \"\"\n",
    "        for z in range(len(self.layers)):\n",
    "            string = string + self.layers[z][\"type\"] + \" | \"\n",
    "        \n",
    "        return string\n",
    "\n",
    "    def initialization(self):\n",
    "        out_channel = np.random.randint(3, self.max_out_ch)\n",
    "        conv_kernel = np.random.randint(3, self.max_conv_kernel)\n",
    "        \n",
    "        # First layer is always a convolution layer\n",
    "        self.layers.append({\"type\": \"conv\", \"ou_c\": out_channel, \"kernel\": conv_kernel})\n",
    "\n",
    "        conv_prob = self.conv_prob\n",
    "        pool_prob = conv_prob + self.pool_prob\n",
    "        fc_prob = pool_prob\n",
    "\n",
    "        for i in range(1, self.depth):\n",
    "            if self.layers[-1][\"type\"] == \"fc\":\n",
    "                layer_type = 1.1\n",
    "            else:\n",
    "                layer_type = np.random.rand()\n",
    "\n",
    "            if layer_type < conv_prob:\n",
    "                self.layers = utils.add_conv(self.layers, self.max_out_ch, self.max_conv_kernel)\n",
    "\n",
    "            elif layer_type >= conv_prob and layer_type <= pool_prob:\n",
    "                self.layers, self.num_pool_layers = utils.add_pool(self.layers, self.fc_prob, self.num_pool_layers, self.max_pool_layers, self.max_out_ch, self.max_conv_kernel, self.max_fc_neurons, self.output_dim)\n",
    "            \n",
    "            elif layer_type >= fc_prob:\n",
    "                self.layers = utils.add_fc(self.layers, self.max_fc_neurons)\n",
    "            \n",
    "        self.layers[-1] = {\"type\": \"fc\", \"ou_c\": self.output_dim, \"kernel\": -1}\n",
    "    \n",
    "\n",
    "    def velocity(self, gBest, Cg):\n",
    "        self.vel = utils.computeVelocity(gBest, self.pBest.layers, self.layers, Cg)\n",
    "\n",
    "    def update(self):\n",
    "        new_p = utils.updateParticle(self.layers, self.vel)\n",
    "        new_p = self.validate(new_p)\n",
    "        \n",
    "        self.layers = new_p\n",
    "        self.model = None\n",
    "\n",
    "    def validate(self, list_layers):\n",
    "        # Last layer should always be a fc with number of neurons equal to the number of outputs\n",
    "        list_layers[-1] = {\"type\": \"fc\", \"ou_c\": self.output_dim, \"kernel\": -1}\n",
    "\n",
    "        # Remove excess of Pooling layers\n",
    "        self.num_pool_layers = 0\n",
    "        for i in range(len(list_layers)):\n",
    "            if list_layers[i][\"type\"] == \"max_pool\" or list_layers[i][\"type\"] == \"avg_pool\":\n",
    "                self.num_pool_layers += 1\n",
    "            \n",
    "                if self.num_pool_layers >= self.max_pool_layers:\n",
    "                    list_layers[i][\"type\"] = \"remove\"\n",
    "\n",
    "\n",
    "        # Now, fix the inputs of each conv and pool layers\n",
    "        updated_list_layers = []\n",
    "        \n",
    "        for i in range(0, len(list_layers)):\n",
    "            if list_layers[i][\"type\"] != \"remove\":\n",
    "                if list_layers[i][\"type\"] == \"conv\":\n",
    "                    updated_list_layers.append({\"type\": \"conv\", \"ou_c\": list_layers[i][\"ou_c\"], \"kernel\": list_layers[i][\"kernel\"]})\n",
    "                \n",
    "                if list_layers[i][\"type\"] == \"fc\":\n",
    "                    updated_list_layers.append(list_layers[i])\n",
    "\n",
    "                if list_layers[i][\"type\"] == \"max_pool\":\n",
    "                    updated_list_layers.append({\"type\": \"max_pool\", \"ou_c\": -1, \"kernel\": 2})\n",
    "\n",
    "                if list_layers[i][\"type\"] == \"avg_pool\":\n",
    "                    updated_list_layers.append({\"type\": \"avg_pool\", \"ou_c\": -1, \"kernel\": 2})\n",
    "\n",
    "        return updated_list_layers\n",
    "\n",
    "    ##### Model methods ####\n",
    "    def model_compile(self, dropout_rate):\n",
    "        list_layers = self.layers\n",
    "        self.model = Sequential()\n",
    "\n",
    "        for i in range(len(list_layers)):\n",
    "            if list_layers[i][\"type\"] == \"conv\":\n",
    "                n_out_filters = list_layers[i][\"ou_c\"]\n",
    "                kernel_size = list_layers[i][\"kernel\"]\n",
    "\n",
    "                if i == 0:\n",
    "                    in_w = self.input_width\n",
    "                    #in_h = self.input_height\n",
    "                    in_c = self.input_channels\n",
    "                    self.model.add(Conv1D(n_out_filters, kernel_size,padding=\"same\" ,data_format=\"channels_last\", kernel_initializer='he_normal', bias_initializer='he_normal', activation=None, input_shape=(in_w, in_c)))\n",
    "                    self.model.add(BatchNormalization())\n",
    "                    self.model.add(Activation(\"relu\"))\n",
    "                else:\n",
    "                    self.model.add(Dropout(dropout_rate))\n",
    "                    self.model.add(Conv1D(n_out_filters, kernel_size,padding=\"same\", kernel_initializer='he_normal', bias_initializer='he_normal', activation=None))\n",
    "                    self.model.add(BatchNormalization())\n",
    "                    self.model.add(Activation(\"relu\"))\n",
    "\n",
    "            if list_layers[i][\"type\"] == \"max_pool\":\n",
    "                kernel_size = list_layers[i][\"kernel\"]\n",
    "\n",
    "                self.model.add(MaxPooling1D(pool_size=3, strides=2))\n",
    "\n",
    "            if list_layers[i][\"type\"] == \"avg_pool\":\n",
    "                kernel_size = list_layers[i][\"kernel\"]\n",
    "\n",
    "                self.model.add(AveragePooling1D(pool_size=3, strides=2))\n",
    "            \n",
    "            if list_layers[i][\"type\"] == \"fc\":\n",
    "                if list_layers[i-1][\"type\"] != \"fc\":\n",
    "                    self.model.add(Flatten())\n",
    "\n",
    "                self.model.add(Dropout(dropout_rate))\n",
    "\n",
    "                if i == len(list_layers) - 1:\n",
    "                    self.model.add(Dense(list_layers[i][\"ou_c\"], kernel_initializer='he_normal', bias_initializer='he_normal', activation=None))\n",
    "                    self.model.add(BatchNormalization())\n",
    "                    self.model.add(Activation(\"softmax\"))\n",
    "                else:\n",
    "                    self.model.add(Dense(list_layers[i][\"ou_c\"], kernel_initializer='he_normal', bias_initializer='he_normal', kernel_regularizer=regularizers.l2(0.01), activation=None))\n",
    "                    self.model.add(BatchNormalization())\n",
    "                    self.model.add(Activation(\"relu\"))\n",
    "\n",
    "        adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, decay=0.0)\n",
    "\n",
    "        self.model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=[\"accuracy\"])\n",
    "    \n",
    "\n",
    "    def model_fit(self, x_train, y_train, batch_size, epochs):\n",
    "        # TODO: add option to only use a sample size of the dataset\n",
    "\n",
    "        hist = self.model.fit(x=x_train, y=y_train, validation_split=0.0, batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "        return hist\n",
    "\n",
    "    def model_fit_complete(self, x_train, y_train, batch_size, epochs):\n",
    "        hist = self.model.fit(x=x_train, y=y_train, validation_split=0.0, batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "        return hist\n",
    "    \n",
    "    def model_delete(self):\n",
    "        # This is used to free up memory during PSO training\n",
    "        del self.model\n",
    "        keras.backend.clear_session()\n",
    "        self.model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L4mRFwTKqP6t"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.datasets import cifar10\n",
    "import keras.backend\n",
    "\n",
    "#from population import Population\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "class psoCNN:\n",
    "    def __init__(self, dataset, n_iter, pop_size, batch_size, epochs, min_layer, max_layer, \\\n",
    "        conv_prob, pool_prob, fc_prob, max_conv_kernel, max_out_ch, max_fc_neurons, dropout_rate):\n",
    "        \n",
    "        self.pop_size = pop_size\n",
    "        self.n_iter = n_iter\n",
    "        self.epochs = epochs\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.gBest_acc = np.zeros(n_iter)\n",
    "        self.gBest_test_acc = np.zeros(n_iter)\n",
    "\n",
    "        if dataset == \"mnist\":\n",
    "            input_width = 28\n",
    "            input_height = 28\n",
    "            input_channels = 1\n",
    "            output_dim = 10\n",
    "\n",
    "            (self.x_train, self.y_train), (self.x_test, self.y_test) = mnist.load_data()\n",
    "        \n",
    "        if dataset == \"HAR\":\n",
    "            print('coming to HAR *********************')\n",
    "            input_width = 128\n",
    "            input_height = 28\n",
    "            input_channels = 9\n",
    "            output_dim = 6\n",
    "            self.x_train = X_train\n",
    "            self.x_test = X_val\n",
    "            print(self.x_train.shape)\n",
    "            print(self.x_test.shape)\n",
    "\n",
    "            #(self.x_train, self.y_train), (self.x_test, self.y_test) = fashion_mnist.load_data()\n",
    "            \n",
    "            #train_x.shape,test_x.shape,train_y.shape, test_y.shape\n",
    "\n",
    "            #self.x_train = self.x_train.astype('float32')\n",
    "            #self.x_test = self.x_test.astype('float32')\n",
    "            #self.x_train /= 255\n",
    "            #self.x_test /= 255\n",
    "\n",
    "        if dataset == \"mnist-background-images\":\n",
    "            input_width = 28\n",
    "            input_height = 28\n",
    "            input_channels = 1\n",
    "            output_dim = 10\n",
    "\n",
    "            train = np.loadtxt(\"./datasets/mnist-background-images/mnist_background_images_train.amat\")\n",
    "            test = np.loadtxt(\"./datasets/mnist-background-images/mnist_background_images_test.amat\")\n",
    "\n",
    "            self.x_train = train[:, :-1]\n",
    "            self.x_test = test[:, :-1]\n",
    "\n",
    "            # Reshape images to 28x28\n",
    "            self.x_train = np.reshape(self.x_train, (-1, 28, 28))\n",
    "            self.x_test = np.reshape(self.x_test, (-1, 28, 28))\n",
    "\n",
    "            self.y_train = train[:, -1]\n",
    "            self.y_test = test[:, -1]\n",
    "\n",
    "        if dataset == \"mnist-rotated-digits\":\n",
    "            input_width = 28\n",
    "            input_height = 28\n",
    "            input_channels = 1\n",
    "            output_dim = 10\n",
    "\n",
    "            train = np.loadtxt(\"./datasets/mnist-rotated-digits/mnist_all_rotation_normalized_float_train_valid.amat\")\n",
    "            test = np.loadtxt(\"./datasets/mnist-rotated-digits/mnist_all_rotation_normalized_float_test.amat\")\n",
    "\n",
    "            self.x_train = train[:, :-1]\n",
    "            self.x_test = test[:, :-1]\n",
    "\n",
    "            # Reshape images to 28x28\n",
    "            self.x_train = np.reshape(self.x_train, (-1, 28, 28))\n",
    "            self.x_test = np.reshape(self.x_test, (-1, 28, 28))\n",
    "\n",
    "            self.y_train = train[:, -1]\n",
    "            self.y_test = test[:, -1]\n",
    "\n",
    "        if dataset == \"mnist-random-background\":\n",
    "            input_width = 28\n",
    "            input_height = 28\n",
    "            input_channels = 1\n",
    "            output_dim = 10\n",
    "\n",
    "            train = np.loadtxt(\"./datasets/mnist-random-background/mnist_background_random_train.amat\")\n",
    "            test = np.loadtxt(\"./datasets/mnist-random-background/mnist_background_random_test.amat\")\n",
    "\n",
    "            self.x_train = train[:, :-1]\n",
    "            self.x_test = test[:, :-1]\n",
    "\n",
    "            # Reshape images to 28x28\n",
    "            self.x_train = np.reshape(self.x_train, (-1, 28, 28))\n",
    "            self.x_test = np.reshape(self.x_test, (-1, 28, 28))\n",
    "\n",
    "            self.y_train = train[:, -1]\n",
    "            self.y_test = test[:, -1]\n",
    "\n",
    "        if dataset == \"mnist-rotated-with-background\":\n",
    "            input_width = 28\n",
    "            input_height = 28\n",
    "            input_channels = 1\n",
    "            output_dim = 10\n",
    "\n",
    "            train = np.loadtxt(\"./datasets/mnist-rotated-with-background/mnist_all_background_images_rotation_normalized_train_valid.amat\")\n",
    "            test = np.loadtxt(\"./datasets/mnist-rotated-with-background/mnist_all_background_images_rotation_normalized_test.amat\")\n",
    "\n",
    "            self.x_train = train[:, :-1]\n",
    "            self.x_test = test[:, :-1]\n",
    "\n",
    "            # Reshape images to 28x28\n",
    "            self.x_train = np.reshape(self.x_train, (-1, 28, 28))\n",
    "            self.x_test = np.reshape(self.x_test, (-1, 28, 28))\n",
    "\n",
    "            self.y_train = train[:, -1]\n",
    "            self.y_test = test[:, -1]\n",
    "\n",
    "        if dataset == \"rectangles\":\n",
    "            print('*********** coming to rectangles **************')\n",
    "            input_width = 28\n",
    "            input_height = 28\n",
    "            input_channels = 1\n",
    "            output_dim = 2\n",
    "\n",
    "            train = np.loadtxt(\"./datasets/rectangles/rectangles_train.amat\")\n",
    "            test = np.loadtxt(\"./datasets/rectangles/rectangles_test.amat\")\n",
    "\n",
    "            self.x_train = train[:, :-1]\n",
    "            self.x_test = test[:, :-1]\n",
    "            print('*********** coming to rectangles **************')\n",
    "            print(self.x_train.shape)\n",
    "            print(self.x_test.shape)\n",
    "\n",
    "            # Reshape images to 28x28\n",
    "            self.x_train = np.reshape(self.x_train, (-1, 28, 28))\n",
    "            self.x_test = np.reshape(self.x_test, (-1, 28, 28))\n",
    "\n",
    "            self.y_train = train[:, -1]\n",
    "            self.y_test = test[:, -1]\n",
    "            print(self.y_train.shape)\n",
    "            print(self.y_test.shape)\n",
    "\n",
    "        if dataset == \"rectangles-images\":\n",
    "            input_width = 28\n",
    "            input_height = 28\n",
    "            input_channels = 1\n",
    "            output_dim = 2\n",
    "\n",
    "            train = np.loadtxt(\"./datasets/rectangles-images/rectangles_im_train.amat\")\n",
    "            test = np.loadtxt(\"./datasets/rectangles-images/rectangles_im_test.amat\")\n",
    "\n",
    "            self.x_train = train[:, :-1]\n",
    "            self.x_test = test[:, :-1]\n",
    "\n",
    "            # Reshape images to 28x28\n",
    "            self.x_train = np.reshape(self.x_train, (-1, 28, 28))\n",
    "            self.x_test = np.reshape(self.x_test, (-1, 28, 28))\n",
    "\n",
    "            self.y_train = train[:, -1]\n",
    "            self.y_test = test[:, -1]\n",
    "\n",
    "        if dataset == \"convex\":\n",
    "            input_width = 28\n",
    "            input_height = 28\n",
    "            input_channels = 1\n",
    "            output_dim = 2\n",
    "\n",
    "            train = np.loadtxt(\"./datasets/convex/convex_train.amat\")\n",
    "            test = np.loadtxt(\"./datasets/convex/convex_test.amat\")\n",
    "\n",
    "            self.x_train = train[:, :-1]\n",
    "            self.x_test = test[:, :-1]\n",
    "\n",
    "            # Reshape images to 28x28\n",
    "            self.x_train = np.reshape(self.x_train, (-1, 28, 28))\n",
    "            self.x_test = np.reshape(self.x_test, (-1, 28, 28))\n",
    "\n",
    "            self.y_train = train[:, -1]\n",
    "            self.y_test = test[:, -1]\n",
    "\n",
    "        #self.x_train = self.x_train.reshape(self.x_train.shape[0], self.x_train.shape[1], self.x_train.shape[2], input_channels)\n",
    "        #self.x_test = self.x_test.reshape(self.x_test.shape[0], self.x_test.shape[1], self.x_test.shape[2], input_channels)\n",
    "\n",
    "        #self.y_train = keras.utils.to_categorical(self.y_train, output_dim)\n",
    "        #self.y_test = keras.utils.to_categorical(self.y_test, output_dim)\n",
    "        self.y_train = Y_train\n",
    "        self.y_test = Y_val\n",
    "        print(self.y_train.shape)\n",
    "        print(self.y_test.shape)\n",
    "\n",
    "\n",
    "        print(\"Initializing population...\")\n",
    "        self.population = Population(pop_size, min_layer, max_layer, input_width, input_channels, conv_prob, pool_prob, fc_prob, max_conv_kernel, max_out_ch, max_fc_neurons, output_dim)\n",
    "        #X_train.shape,Y_train.shape, X_val.shape, Y_val.shape\n",
    "        print(\"Verifying accuracy of the current gBest...\")\n",
    "        print(self.population.particle[0])\n",
    "        self.gBest = deepcopy(self.population.particle[0])\n",
    "        self.gBest.model_compile(dropout_rate)\n",
    "        print(self.x_train.shape)\n",
    "        print(self.y_train.shape)\n",
    "        print(self.x_test.shape)\n",
    "        print(self.y_test.shape)\n",
    "        hist = self.gBest.model_fit(self.x_train, self.y_train, batch_size=batch_size, epochs=epochs)\n",
    "        test_metrics = self.gBest.model.evaluate(x=self.x_test, y=self.y_test, batch_size=batch_size)\n",
    "        self.gBest.model_delete()\n",
    "\n",
    "\n",
    "        history_dict = hist.history\n",
    "        print(history_dict.keys())\n",
    "        print('************* coming to dict keys *************')\n",
    "        self.gBest_acc[0] = hist.history['accuracy'][-1]\n",
    "        history_dict = hist.history\n",
    "        print(history_dict.keys())\n",
    "        self.gBest_test_acc[0] = test_metrics[1]\n",
    "        \n",
    "        self.population.particle[0].acc = hist.history['accuracy'][-1]\n",
    "        self.population.particle[0].pBest.acc = hist.history['accuracy'][-1]\n",
    "\n",
    "        print(\"Current gBest acc: \" + str(self.gBest_acc[0]) + \"\\n\")\n",
    "        print(\"Current gBest test acc: \" + str(self.gBest_test_acc[0]) + \"\\n\")\n",
    "\n",
    "        print(\"Looking for a new gBest in the population...\")\n",
    "        for i in range(1, self.pop_size):\n",
    "            print('Initialization - Particle: ' + str(i+1))\n",
    "            print(self.population.particle[i])\n",
    "\n",
    "            self.population.particle[i].model_compile(dropout_rate)\n",
    "            hist = self.population.particle[i].model_fit(self.x_train, self.y_train, batch_size=batch_size, epochs=epochs)\n",
    "           \n",
    "            self.population.particle[i].acc = hist.history['accuracy'][-1]\n",
    "            self.population.particle[i].pBest.acc = hist.history['accuracy'][-1]\n",
    "\n",
    "            if self.population.particle[i].pBest.acc >= self.gBest_acc[0]:\n",
    "                print(\"Found a new gBest.\")\n",
    "                self.gBest = deepcopy(self.population.particle[i])\n",
    "                self.gBest_acc[0] = self.population.particle[i].pBest.acc\n",
    "                print(\"New gBest acc: \" + str(self.gBest_acc[0]))\n",
    "\n",
    "                test_metrics = self.gBest.model.evaluate(x=self.x_test, y=self.y_test, batch_size=batch_size)\n",
    "                self.gBest_test_acc[0] = test_metrics[1]\n",
    "                print(\"New gBest test acc: \" + str(self.gBest_acc[0]))\n",
    "            \n",
    "            self.population.particle[i].model_delete()\n",
    "            self.gBest.model_delete()\n",
    "\n",
    "\n",
    "    def fit(self, Cg, dropout_rate):\n",
    "        for i in range(1, self.n_iter):            \n",
    "            gBest_acc = self.gBest_acc[i-1]\n",
    "            gBest_test_acc = self.gBest_test_acc[i-1]\n",
    "\n",
    "            for j in range(self.pop_size):\n",
    "                print('Iteration: ' + str(i) + ' - Particle: ' + str(j+1))\n",
    "\n",
    "                # Update particle velocity\n",
    "                self.population.particle[j].velocity(self.gBest.layers, Cg)\n",
    "\n",
    "                # Update particle architecture\n",
    "                self.population.particle[j].update()\n",
    "\n",
    "                print('Particle NEW architecture: ')\n",
    "                print(self.population.particle[j])\n",
    "\n",
    "                # Compute the acc in the updated particle\n",
    "                self.population.particle[j].model_compile(dropout_rate)\n",
    "                hist = self.population.particle[j].model_fit(self.x_train, self.y_train, batch_size=self.batch_size, epochs=self.epochs)\n",
    "                self.population.particle[j].model_delete()\n",
    "\n",
    "                self.population.particle[j].acc = hist.history['accuracy'][-1]\n",
    "            \n",
    "                f_test = self.population.particle[j].acc\n",
    "                pBest_acc = self.population.particle[j].pBest.acc\n",
    "\n",
    "                if f_test >= pBest_acc:\n",
    "                    print(\"Found a new pBest.\")\n",
    "                    print(\"Current acc: \" + str(f_test))\n",
    "                    print(\"Past pBest acc: \" + str(pBest_acc))\n",
    "                    pBest_acc = f_test\n",
    "                    self.population.particle[j].pBest = deepcopy(self.population.particle[j])\n",
    "\n",
    "                    if pBest_acc >= gBest_acc:\n",
    "                        print(\"Found a new gBest.\")\n",
    "                        gBest_acc = pBest_acc\n",
    "                        self.gBest = deepcopy(self.population.particle[j])\n",
    "                        self.gBest.model_compile(dropout_rate)\n",
    "                        hist = self.gBest.model_fit(self.x_train, self.y_train, batch_size=self.batch_size, epochs=self.epochs)\n",
    "                        test_metrics = self.gBest.model.evaluate(x=self.x_test, y=self.y_test, batch_size=self.batch_size)\n",
    "                        self.gBest.model_delete()\n",
    "                        gBest_test_acc = test_metrics[1]\n",
    "\n",
    "                \n",
    "            self.gBest_acc[i] = gBest_acc\n",
    "            self.gBest_test_acc[i] = gBest_test_acc\n",
    "\n",
    "            print(\"Current gBest acc: \" + str(self.gBest_acc[i]))\n",
    "            print(\"Current gBest test acc: \" + str(self.gBest_test_acc[i]))\n",
    "\n",
    "    def fit_gBest(self, batch_size, epochs, dropout_rate):\n",
    "        print(\"\\nFurther training gBest model...\")\n",
    "        self.gBest.model_compile(dropout_rate)        \n",
    "        trainable_count = int(np.sum([keras.backend.count_params(p) for p in set(self.gBest.model.trainable_weights)]))\n",
    "        print(\"gBest's number of trainable parameters: \" + str(trainable_count))\n",
    "        self.gBest.model_fit_complete(self.x_train, self.y_train, batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "        return trainable_count\n",
    "    \n",
    "    def evaluate_gBest(self, batch_size):\n",
    "        print(\"\\nEvaluating gBest model on the test set...\")\n",
    "        \n",
    "        metrics = self.gBest.model.evaluate(x=self.x_test, y=self.y_test, batch_size=batch_size)\n",
    "\n",
    "        print(\"\\ngBest model loss in the test set: \" + str(metrics[0]) + \" - Test set accuracy: \" + str(metrics[1]))\n",
    "        return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 835
    },
    "colab_type": "code",
    "id": "0kgRxbyq6rrm",
    "outputId": "2224a2b8-ba98-45b8-c833-991054698b7b"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "pip install tensorflow==1.14.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "-gBl9ODG9v2u",
    "outputId": "55025102-bf41-4bed-8353-1d77125349bb"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "EzqHFzNzXK6w",
    "outputId": "4700e911-654e-4695-8742-923585492314"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.7.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    ######## Algorithm parameters ##################\n",
    "    \n",
    "    # dataset = \"mnist\"\n",
    "    # dataset = \"mnist-rotated-digits\"\n",
    "    # dataset = \"mnist-rotated-with-background\"\n",
    "    dataset = \"HAR\"\n",
    "    # dataset = \"rectangles-images\"\n",
    "    #dataset = \"convex\"\n",
    "    # dataset = \"fashion-mnist\"\n",
    "    # dataset = \"mnist-random-background\"\n",
    "    # dataset = \"mnist-background-images\"\n",
    "    \n",
    "    number_runs = 10\n",
    "    number_iterations = 5\n",
    "    population_size = 20\n",
    "    batch_size_pso = 32\n",
    "    batch_size_full_training = 32\n",
    "    \n",
    "    epochs_pso = 1\n",
    "    epochs_full_training = 100\n",
    "    \n",
    "    max_conv_output_channels = 264\n",
    "    max_fully_connected_neurons = 300\n",
    "    min_layer = 3\n",
    "    max_layer = 20\n",
    "\n",
    "    # Probability of each layer type (should sum to 1)\n",
    "    probability_convolution = 0.6\n",
    "    probability_pooling = 0.3\n",
    "    probability_fully_connected = 0.1\n",
    "    max_conv_kernel_size = 7\n",
    "    Cg = 0.5\n",
    "    dropout = 0.5\n",
    "\n",
    "    ########### Run the algorithm ######################\n",
    "    results_path = \"./results/\" + dataset + \"/\"\n",
    "    if not os.path.exists(results_path):\n",
    "            os.makedirs(results_path)\n",
    "    all_gBest_metrics = np.zeros((number_runs, 2))\n",
    "    runs_time = []\n",
    "    all_gbest_par = []\n",
    "    best_gBest_acc = 0\n",
    "    for i in range(number_runs):\n",
    "        print(\"Run number: \" + str(i))\n",
    "        start_time = time.time()\n",
    "        pso = psoCNN(dataset=dataset, n_iter=number_iterations, pop_size=population_size,\n",
    "                     batch_size=batch_size_pso, epochs=epochs_pso, min_layer=min_layer, max_layer=max_layer,\n",
    "                     conv_prob=probability_convolution, pool_prob=probability_pooling,\n",
    "                     fc_prob=probability_fully_connected, max_conv_kernel=max_conv_kernel_size,\n",
    "                     max_out_ch=max_conv_output_channels, max_fc_neurons=max_fully_connected_neurons,\n",
    "                     dropout_rate=dropout)\n",
    "        pso.fit(Cg=Cg, dropout_rate=dropout)\n",
    "        print(pso.gBest_acc)\n",
    "\n",
    "        # Plot current gBest\n",
    "        matplotlib.use('Agg')\n",
    "        plt.plot(pso.gBest_acc)\n",
    "        plt.xlabel(\"Iteration\")\n",
    "        plt.ylabel(\"gBest acc\")\n",
    "        plt.savefig(results_path + \"gBest-iter-\" + str(i) + \".png\")\n",
    "        plt.close()\n",
    "        print('gBest architecture: ')\n",
    "        print(pso.gBest)\n",
    "    \n",
    "        np.save(results_path + \"gBest_inter_\" + str(i) + \"_acc_history.npy\", pso.gBest_acc)\n",
    "        np.save(results_path + \"gBest_iter_\" + str(i) + \"_test_acc_history.npy\", pso.gBest_test_acc)\n",
    "        end_time = time.time()\n",
    "        running_time = end_time - start_time\n",
    "        runs_time.append(running_time)\n",
    "\n",
    "        # Fully train the gBest model found\n",
    "        n_parameters = pso.fit_gBest(batch_size=batch_size_full_training, epochs=epochs_full_training, dropout_rate=dropout)\n",
    "        all_gbest_par.append(n_parameters)\n",
    "\n",
    "        # Evaluate the fully trained gBest model\n",
    "        gBest_metrics = pso.evaluate_gBest(batch_size=batch_size_full_training)\n",
    "        if gBest_metrics[1] >= best_gBest_acc:\n",
    "            best_gBest_acc = gBest_metrics[1]\n",
    "\n",
    "            # Save best gBest model\n",
    "            best_gBest_yaml = pso.gBest.model.to_yaml()\n",
    "            with open(results_path + \"best-gBest-model.yaml\", \"w\") as yaml_file:\n",
    "                yaml_file.write(best_gBest_yaml)\n",
    "            \n",
    "            # Save best gBest model weights to HDF5 file\n",
    "            pso.gBest.model.save_weights(results_path + \"best-gBest-weights.h5\")\n",
    "        all_gBest_metrics[i, 0] = gBest_metrics[0]\n",
    "        all_gBest_metrics[i, 1] = gBest_metrics[1]\n",
    "        print(\"This run took: \" + str(running_time) + \" seconds.\")\n",
    "         # Compute mean accuracy of all runs\n",
    "        all_gBest_mean_metrics = np.mean(all_gBest_metrics, axis=0)\n",
    "        np.save(results_path + \"/time_to_run.npy\", runs_time)\n",
    "\n",
    "        # Save all gBest metrics\n",
    "        np.save(results_path + \"/all_gBest_metrics.npy\", all_gBest_metrics)\n",
    "\n",
    "        # Save results in a text file\n",
    "        output_str = \"All gBest number of parameters: \" + str(all_gbest_par) + \"\\n\"\n",
    "        output_str = output_str + \"All gBest test accuracies: \" + str(all_gBest_metrics[:,1]) + \"\\n\"\n",
    "        output_str = output_str + \"All running times: \" + str(runs_time) + \"\\n\"\n",
    "        output_str = output_str + \"Mean loss of all runs: \" + str(all_gBest_mean_metrics[0]) + \"\\n\"\n",
    "        output_str = output_str + \"Mean accuracy of all runs: \" + str(all_gBest_mean_metrics[1]) + \"\\n\"\n",
    "        print(output_str)\n",
    "        with open(results_path + \"/final_results.txt\", \"w\") as f:\n",
    "            try:\n",
    "                print(output_str, file=f)\n",
    "            except SyntaxError:\n",
    "                print >> f, output_str"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "uTySIvbfu053",
    "_Qz5oCvZu06-"
   ],
   "name": "Copy_of_Human_Activity_Detection_Without_Verbose_.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
